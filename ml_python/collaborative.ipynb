{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28797533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('')\n",
    "df_users = pd.read_csv('')\n",
    "df_item = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c675262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "display(df.head())\n",
    "display(df_item.head())\n",
    "display(df_users.head())\n",
    "\n",
    "print('Min:\\t\\t', df_users['personId'].value_counts().min())\n",
    "print('Quartile 1:\\t', df_users['personId'].value_counts().quantile(.25))\n",
    "print('Median:\\t\\t', df_users['personId'].value_counts().quantile(.5))\n",
    "print('Quartile 3:\\t', df_users['personId'].value_counts().quantile(.75))\n",
    "print('Max:\\t\\t', df_users['personId'].value_counts().max())\n",
    "\n",
    "# use these values to determine what data we keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d195b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df_users.contentId.value_counts()\n",
    "keep_list = value_counts[value_counts >= 9]\n",
    "df_users_reduced = df_users.loc[df_users.contentId.isin(keep_list.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47061c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matrix and mapper\n",
    "def create_matrix(df, user, item, rating):\n",
    "  import numpy as np\n",
    "  from scipy.sparse import csr_matrix\n",
    "\n",
    "  U = df[user].nunique()  # Number of users for the matrix\n",
    "  I = df[item].nunique()  # Number of items for the matrix\n",
    "\n",
    "  # Map user and movie IDs to matrix indices\n",
    "  user_mapper = dict(zip(np.unique(df[user]), list(range(U))))\n",
    "  item_mapper = dict(zip(np.unique(df[item]), list(range(I))))\n",
    "\n",
    "  # Map matrix indices back to IDs\n",
    "  user_inv_mapper = dict(zip(list(range(U)), np.unique(df[user])))\n",
    "  item_inv_mapper = dict(zip(list(range(I)), np.unique(df[item])))\n",
    "\n",
    "  # Create a list of index values for the csr_matrix for users and movies\n",
    "  user_index = [user_mapper[i] for i in df[user]]\n",
    "  item_index = [item_mapper[i] for i in df[item]]\n",
    "\n",
    "  # Build the final matrix which will look like: (movieId, userId) rating\n",
    "  X = csr_matrix((df[rating], (item_index, user_index)), shape=(I, U))\n",
    "\n",
    "  return X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99de577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by columns to include in model\n",
    "X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper = create_matrix(df_users_reduced, 'personId', 'contentId', 'eventType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28eff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender based on item\n",
    "def recommend(itemId, X, item_mapper, item_inv_mapper, k, metric='cosine', messages=True):\n",
    "  from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "  rec_ids = []                # Make a list for the recommended item IDs we'll get later\n",
    "  item = item_mapper[itemId]  # Get the index of the movie ID passed into the function\n",
    "  item_vector = X[item]       # Get the vector of user ratings for the movie ID passed into the function\n",
    "\n",
    "  # Fit the clustering algorithm based on the user-item matrix X\n",
    "  knn = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric).fit(X)\n",
    "\n",
    "  # Call the trained knn cluster model to return the nearest neighbors of the item_vector passed in\n",
    "  rec = knn.kneighbors(item_vector.reshape(1,-1), return_distance=True)\n",
    "  rec_indeces = rec[1][0]     # Parse out the list of indeces of the recommended items\n",
    "  rec_distances = rec[0][0]   # Parse out the recommendation strength calculated as the distance from the cluster center\n",
    "  rec_distances = np.delete(rec_distances, 0) # Drop the first number in the list because it is the distance of itemId from itself\n",
    "\n",
    "  # We need to replace the recommended item indeces with their original item IDs\n",
    "  for i in range(1, knn.n_neighbors): # n_neighbors is the number of neighbors to return\n",
    "    rec_ids.append(item_inv_mapper[rec_indeces[i]])\n",
    "\n",
    "  # It may help to see what this is. The distance list is first and the recommended item indeces are second\n",
    "  if messages:\n",
    "    print(f'List of recommended item indeces:\\n{rec_indeces}\\n')\n",
    "    print(f'List of recommended item IDs:\\n{rec_ids}\\n')\n",
    "    print(f'List of recommended item similarity to selected item:\\n{rec_distances}\\n')\n",
    "\n",
    "  # Return two lists: the original item IDs of the recommendations and their similarity scores\n",
    "  return rec_ids, rec_distances\n",
    "\n",
    "content_Id = 1 # Change here for testing\n",
    "rec_ids, rec_distances = recommend(content_Id, X, item_mapper, item_inv_mapper, k=10, messages=False)\n",
    "\n",
    "# Change dataframe here for predictions\n",
    "print(f\"If you like {df_articles.loc[content_Id, 'title']}, you may also enjoy:\\n\")\n",
    "df_articles.loc[rec_ids, 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender based on user\n",
    "user_id = -1130272294246983140\n",
    "k = 20\n",
    "\n",
    "df_user_ratings = df_users_reduced.loc[df_users_reduced['personId']==user_id].sort_values(by=['eventType'], ascending=False)\n",
    "max_rating = df_user_ratings.eventType.max()\n",
    "df_user_ratings = df_user_ratings.loc[df_user_ratings.eventType==max_rating]\n",
    "\n",
    "df_rec_list = pd.DataFrame(columns=['Distance'])\n",
    "\n",
    "for i in df_user_ratings.contentId:\n",
    "  rec_ids, rec_distances = recommend(i, X, item_mapper, item_inv_mapper, k=10, messages=False)\n",
    "  for j, movie in enumerate(rec_ids):\n",
    "    df_rec_list.loc[movie] = rec_distances[j]\n",
    "\n",
    "df_rec_list.sort_values(by=['Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a10bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendation on item\n",
    "k = 5\n",
    "\n",
    "df_recommendations = pd.DataFrame(columns=['If you enjoyed'], index=item_mapper)\n",
    "for i in range(1, (k + 1)):\n",
    "  df_recommendations[f'Recommendation {i}'] = None\n",
    "\n",
    "for row in df_recommendations.itertuples():\n",
    "  rec_ids, rec_distances = recommend(row[0], X, item_mapper, item_inv_mapper, k=k, messages=False)\n",
    "\n",
    "  df_recommendations.at[row[0], 'If you enjoyed'] = df_articles.at[row[0], 'title']\n",
    "\n",
    "  for i, r in enumerate(rec_ids):\n",
    "    df_recommendations.at[row[0], f\"Recommendation {i + 1}\"] = df_articles.at[r, 'title']\n",
    "\n",
    "df_recommendations\n",
    "df_recommendations.to_csv('collabortive_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cc568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047827d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
